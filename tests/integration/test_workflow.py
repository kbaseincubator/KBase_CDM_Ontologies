"""Integration tests for the complete workflow."""

import os
import pytest
from pathlib import Path
import sys
import json
from unittest.mock import Mock, patch

# Add modules to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../'))

from cdm_ontologies.cli import run_all

class TestWorkflowIntegration:
    """Test complete workflow integration."""
    
    @pytest.fixture
    def setup_test_environment(self, temp_repo, monkeypatch):
        """Set up a complete test environment."""
        # Set environment variables
        monkeypatch.setenv("DATASET_SIZE", "test")
        monkeypatch.setenv("ONTOLOGIES_SOURCE_FILE", "config/ontologies_source_test.txt")
        monkeypatch.setenv("SKIP_NON_CORE_ANALYSIS", "true")
        monkeypatch.setenv("ROBOT_JAVA_ARGS", "-Xmx2g")
        monkeypatch.setenv("SKIP_RESOURCE_CHECK", "true")
        monkeypatch.setenv("ENABLE_MEMORY_MONITORING", "false")
        
        # Create required directories
        (temp_repo / "logs").mkdir(exist_ok=True)
        (temp_repo / "config").mkdir(exist_ok=True)
        
        # Create test ontology source file
        source_file = temp_repo / "config" / "ontologies_source_test.txt"
        source_file.write_text("""# Test ontologies
go
chebi
uberon
""")
        
        # Note: merge_ontologies will create the merged list file in config/
        
        # Create prefix mapping
        prefix_file = temp_repo / "prefix_mapping.txt"
        prefix_file.write_text("""GO\thttp://purl.obolibrary.org/obo/go#
CHEBI\thttp://purl.obolibrary.org/obo/chebi#
UBERON\thttp://purl.obolibrary.org/obo/uberon#""")
        
        # Create test OWL files
        owl_dir = temp_repo / "ontology_data_owl_test"
        owl_dir.mkdir(exist_ok=True)
        
        for name in ["go.owl", "chebi.owl", "uberon.owl"]:
            owl_file = owl_dir / name
            owl_file.write_text(f"""<?xml version="1.0"?>
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:owl="http://www.w3.org/2002/07/owl#">
    <owl:Ontology rdf:about="http://purl.obolibrary.org/obo/{name}"/>
    <owl:Class rdf:about="http://purl.obolibrary.org/obo/{name.upper()}_0000001"/>
</rdf:RDF>""")
        
        # Change to temp directory
        monkeypatch.chdir(temp_repo)
        
        return temp_repo
    
    def test_minimal_workflow(self, setup_test_environment, monkeypatch):
        """Test minimal workflow with mocked external tools."""
        temp_repo = setup_test_environment
        
        # Mock shutil.which to find tools
        def mock_which(cmd):
            if cmd in ['robot', 'semsql']:
                return f'/usr/bin/{cmd}'
            return None
        
        monkeypatch.setattr("shutil.which", mock_which)
        
        # Mock os.path.exists to handle OWL file check in outputs directory
        original_exists = os.path.exists
        def mock_exists(path):
            # If checking for CDM_merged_ontologies.owl in outputs_test directory, return True
            if 'CDM_merged_ontologies.owl' in str(path) and 'outputs_test' in str(Path(path).resolve()):
                return True
            return original_exists(path)
        
        monkeypatch.setattr("os.path.exists", mock_exists)
        
        # Mock external tool calls
        def mock_subprocess_run(*args, **kwargs):
            cmd = args[0] if args else kwargs.get('args', [])
            
            # Handle different commands
            if isinstance(cmd, list):
                if 'robot' in str(cmd):
                    # Mock ROBOT command - create output file
                    for i, arg in enumerate(cmd):
                        if arg == '-o' and i + 1 < len(cmd):
                            output_file = Path(cmd[i + 1])
                            output_file.parent.mkdir(parents=True, exist_ok=True)
                            output_file.write_text('<?xml version="1.0"?><rdf:RDF></rdf:RDF>')
                elif 'semsql' in str(cmd):
                    # Mock semsql command - create database
                    # Note: semsql is run in the outputs directory where the OWL file exists
                    for i, arg in enumerate(cmd):
                        if arg == 'make' and i + 1 < len(cmd):
                            # The database file name is relative to current directory
                            db_file = Path(cmd[i + 1])
                            # Create database file in current directory (which is outputs_test)
                            db_file.touch()
            
            # Return success
            class MockResult:
                returncode = 0
                stdout = b"Success"
                stderr = b""
            return MockResult()
        
        monkeypatch.setattr("subprocess.run", mock_subprocess_run)
        
        # Mock process monitoring for memory monitor
        monkeypatch.setattr("subprocess.Popen", lambda *args, **kwargs: Mock(
            poll=lambda: 0,
            wait=lambda: 0,
            returncode=0
        ))
        
        # Create args mock
        args = Mock()
        args.skip_resource_check = True
        args.continue_on_error = False
        
        # Run workflow
        result = run_all(args)
        
        # Verify success
        assert result == 0
        
        # Check key outputs exist
        outputs_dir = temp_repo / "outputs_test"
        assert outputs_dir.exists()
        # The core_ontologies_analysis.json might not be created in minimal test
        # assert (outputs_dir / "core_ontologies_analysis.json").exists()
        assert (outputs_dir / "CDM_merged_ontologies.owl").exists()
    
    def test_workflow_error_handling(self, setup_test_environment, monkeypatch):
        """Test workflow handles errors appropriately."""
        temp_repo = setup_test_environment
        
        # Mock a failing step
        def mock_failing_merge(*args, **kwargs):
            return False
        
        monkeypatch.setattr("cdm_ontologies.cli.merge_ontologies", mock_failing_merge)
        
        # Create args mock without continue_on_error
        args = Mock()
        args.skip_resource_check = True
        args.continue_on_error = False
        
        # Run workflow - should fail at merge step
        result = run_all(args)
        
        assert result == 1
    
    def test_workflow_continue_on_error(self, setup_test_environment, monkeypatch):
        """Test workflow continues when continue_on_error is set."""
        temp_repo = setup_test_environment
        
        # Mock some failing steps
        def mock_failing_merge(*args, **kwargs):
            return False
        
        def mock_failing_db(*args, **kwargs):
            return False
        
        monkeypatch.setattr("cdm_ontologies.cli.merge_ontologies", mock_failing_merge)
        monkeypatch.setattr("cdm_ontologies.cli.create_semantic_sql_db", mock_failing_db)
        
        # Mock successful steps
        monkeypatch.setattr("cdm_ontologies.cli.extract_sql_tables_to_tsv", lambda x: True)
        monkeypatch.setattr("cdm_ontologies.cli.create_parquet_files", lambda x: True)
        
        # Create args mock with continue_on_error
        args = Mock()
        args.skip_resource_check = True
        args.continue_on_error = True
        
        # Run workflow - should complete despite failures
        result = run_all(args)
        
        assert result == 0